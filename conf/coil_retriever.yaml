defaults:
  - encoder: coil_encoder # defines encoder initialization parameters
  - datasets: retriever_default # contains a list of all possible sources of queries for evaluation. Specific set is selected by qa_dataset parameter
  - ctx_sources: default_sources # contains a list of all possible passage sources. Specific passages sources selected by ctx_datatsets parameter

retriever: coil

indexers:
  flat:
    _target_: coil.coil_retriever.COILIndex
    shard_path: /task_runtime/coil/COIL/index
    num_shard: 1

indexer: flat

encoded_ctx_files:

doc_prefixes:

qa_dataset:

out_file:
# "regex" or "string"
match: string
n_docs: 100
validation_workers: 16

# Batch size to generate query embeddings
batch_size: 128

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True

# The attribute name of encoder to use for queries. Options for the BiEncoder model: question_model, ctx_model
# question_model is used if this param is empty
encoder_path:

kilt_out_file:

# A trained bi-encoder checkpoint file to initialize the model
model_file:

validate_as_tables: False
rpc_retriever_cfg_file:

# tokens which won't be slit by tokenizer
special_tokens:

# TODO: move to a conf group
# local_rank for distributed training on gpus
local_rank: -1
global_loss_buf_sz: 150000
device:
distributed_world_size:
no_cuda: False
n_gpu:
fp16: False

# For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']."
#        "See details at https://nvidia.github.io/apex/amp.html
fp16_opt_level: O1

# originally from dpr.data.retriever_data.CsvQASrc object
special_query_token:

selector: